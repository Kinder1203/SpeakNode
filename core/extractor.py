import re
import json
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

class Extractor:
    def __init__(self, model_name="deepseek-r1:14b", base_url="http://localhost:11434"):
        """
        LLM ì¶”ì¶œê¸° ì´ˆê¸°í™”
        :param model_name: ì‚¬ìš©í•  Ollama ëª¨ë¸ëª… (ì˜ˆ: deepseek-r1:14b, llama3)
        :param base_url: Ollama ì„œë²„ ì£¼ì†Œ (RunPod ë‚´ë¶€ì´ë¯€ë¡œ localhost)
        """
        print(f"ğŸ§  [Extractor] Initializing with model: {model_name}...")
        
        # 1. LLM ì„¤ì • (temperature=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ëœ ê²°ê³¼ ìœ ë„)
        self.llm = ChatOllama(
            model=model_name,
            base_url=base_url,
            temperature=0.1,
            format="json"  # JSON ëª¨ë“œ ê°•ì œ
        )
        
        # 2. í”„ë¡¬í”„íŠ¸ ì„¤ê³„ (ê·¸ë˜í”„ DB ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì¶”ì¶œ ì§€ì‹œ)
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """
            ë‹¹ì‹ ì€ íšŒì˜ë¡ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. íšŒì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
            
            [ì¶”ì¶œ ì§€ì¹¨]
            1. people: íšŒì˜ì— ì°¸ì—¬í•œ ëª¨ë“  ì¸ë¬¼ê³¼ ê·¸ë“¤ì˜ ì—­í• ì„ ì¶”ì¶œí•˜ì„¸ìš”.
            2. topics: ë…¼ì˜ëœ ì£¼ì œë¥¼ ì¶”ì¶œí•˜ë˜, í•´ë‹¹ ì£¼ì œë¥¼ ëˆ„ê°€ ì²˜ìŒ êº¼ëƒˆëŠ”ì§€(proposer) ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
            3. decisions/tasks: ê²°ì •ì‚¬í•­ê³¼ í•  ì¼ì„ ì¶”ì¶œí•˜ê³ , ë‹´ë‹¹ì(assignee)ë¥¼ ì—°ê²°í•˜ì„¸ìš”.
            
            [JSON í˜•ì‹]
            {{
                "people": [{{"name": "ì´ë¦„", "role": "ì§ì±…"}}],
                "topics": [{{"title": "ì£¼ì œëª…", "summary": "ìš”ì•½", "proposer": "ì´ë¦„"}}],
                "decisions": [{{"description": "ê²°ì •ì‚¬í•­", "proposer": "ì´ë¦„"}}],
                "tasks": [{{"description": "í•  ì¼", "assignee": "ì´ë¦„", "deadline": "ë‚ ì§œ"}}]
            }}
            """),
            ("user", "{text}")
        ])
        
        # 3. ì²´ì¸ ìƒì„±
        self.chain = self.prompt | self.llm

    def _clean_think_tags(self, text):
        """DeepSeek ëª¨ë¸ì˜ <think> íƒœê·¸ ì œê±°"""
        return re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()

    def extract(self, transcription_text):
        """
        í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ
        """
        print("ğŸ§  [Extractor] Analyzing text...")
        
        try:
            # LLM í˜¸ì¶œ
            response = self.chain.invoke({"text": transcription_text})
            
            # LangChain ê°ì²´ì—ì„œ ì‹¤ì œ ë‚´ìš©(content)ë§Œ ì¶”ì¶œ
            content = response.content if hasattr(response, 'content') else str(response)
            
            # <think> íƒœê·¸ ì œê±° (DeepSeek-R1 ì‚¬ìš© ì‹œ í•„ìˆ˜)
            clean_content = self._clean_think_tags(content)
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                data = json.loads(clean_content)
                print(f"âœ… [Extractor] Extraction successful: {len(data.get('topics', []))} topics found.")
                return data
            except json.JSONDecodeError:
                # JSON í˜•ì‹ì´ ê¹¨ì ¸ì„œ ì˜¬ ê²½ìš°, ë’·ìˆ˜ìŠµ ì‹œë„ (ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë°˜í™˜)
                print("âš ï¸ [Extractor] JSON parsing failed. Returning raw text.")
                return {"raw_summary": clean_content}
                
        except Exception as e:
            print(f"âŒ [Extractor] Error: {e}")
            return {}

# ==========================================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì½”ë“œ
# ==========================================
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ê°€ì§œ íšŒì˜ë¡
    test_text = """
    ê¹€ì² ìˆ˜: ì´ë²ˆ í”„ë¡œì íŠ¸ ì„œë²„ ë¹„ìš©ì´ ë„ˆë¬´ ë§ì´ ë‚˜ì˜µë‹ˆë‹¤.
    ì´ì˜í¬: ê·¸ëŸ¼ ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë„ì…í•´ì„œ ë¹„ìš©ì„ ì¤„ì…ì‹œë‹¤.
    ê¹€ì² ìˆ˜: ì¢‹ì•„ìš”. ì œê°€ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ê¹Œì§€ ë¹„ìš© ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ì˜¬ê²Œìš”.
    ë°•ë¯¼ìˆ˜: ì•Œê² ìŠµë‹ˆë‹¤. ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ ë„ì…ì€ ë°”ë¡œ ì§„í–‰í•˜ëŠ” ê±¸ë¡œ ê²°ì •í•˜ì£ .
    """
    
    # ëª¨ë¸ëª…ì€ RunPodì— ì„¤ì¹˜í•œ ê²ƒê³¼ ì¼ì¹˜í•´ì•¼ í•¨ (ì˜ˆ: deepseek-r1:14b ë˜ëŠ” llama3)
    extractor = Extractor(model_name="deepseek-r1:14b") # ì„¤ì¹˜í•œ ëª¨ë¸ëª… í™•ì¸!
    
    result = extractor.extract(test_text)
    print("\n--- [Extraction Result] ---")
    print(json.dumps(result, indent=2, ensure_ascii=False))