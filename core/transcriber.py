import os
import torch
from faster_whisper import WhisperModel

class Transcriber:
    def __init__(self, model_size="large-v3", device=None):
        """
        Whisper ëª¨ë¸ ì´ˆê¸°í™” (ì„œë²„ êµ¬ë™ ì‹œ 1íšŒ ì‹¤í–‰ë¨)
        """
        # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ (RunPod GPU ìš°ì„ )
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
            
        # GPU ì‚¬ìš© ì‹œ float16, CPU ì‚¬ìš© ì‹œ int8 (ì†ë„ ìµœì í™”)
        compute_type = "float16" if self.device == "cuda" else "int8"
        
        print(f"ğŸš€ [Transcriber] Loading model '{model_size}' on {self.device} ({compute_type})...")
        
        try:
            # ëª¨ë¸ ë¡œë“œ (ë‹¤ìš´ë¡œë“œ ë° ìºì‹± ìë™ ì²˜ë¦¬)
            self.model = WhisperModel(
                model_size, 
                device=self.device, 
                compute_type=compute_type
            )
            print(f"âœ… [Transcriber] Model loaded ready.")
        except Exception as e:
            print(f"âŒ [Transcriber] Critical Error loading model: {e}")
            raise e

    def transcribe(self, audio_path):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ë°˜í™˜
        """
        if not os.path.exists(audio_path):
            print(f"âš ï¸ [Error] File not found: {audio_path}")
            return None

        print(f"ğŸ§ [Transcriber] Processing audio: {os.path.basename(audio_path)}")
        
        # Transcribe ì‹¤í–‰ (beam_size=5ë¡œ ì •í™•ë„ í™•ë³´)
        # language="ko"ë¥¼ ì§€ì •í•˜ë©´ í•œêµ­ì–´ ì¸ì‹ë¥ ì´ ë” ì˜¬ë¼ê°‘ë‹ˆë‹¤.
        segments, info = self.model.transcribe(audio_path, beam_size=5, language="ko")
        
        print(f"   â„¹ï¸ Detected language: '{info.language}' (Probability: {info.language_probability:.2f})")
        
        # Generatorë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (DB ì €ì¥ìš© í¬ë§·íŒ…)
        result_data = []
        for segment in segments:
            # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì²˜ë¦¬
            if segment.text.strip():
                # ì½˜ì†”ì— ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                print(f"   [{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
                
                result_data.append({
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                })
        
        print(f"âœ… [Transcriber] Completed. Total segments: {len(result_data)}")
        return result_data

# ==========================================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì½”ë“œ (RunPodì—ì„œ ì§ì ‘ ì‹¤í–‰ ì‹œ ë™ì‘)
# ==========================================
if __name__ == "__main__":
    # 1. í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ê²½ë¡œ (runpodctlë¡œ ì˜¬ë¦° íŒŒì¼ ì´ë¦„)
    TEST_FILE = "test_audio.mp3"  # ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •
    
    if os.path.exists(TEST_FILE):
        # 2. ëª¨ë¸ ì´ˆê¸°í™” (ê°€ì¥ ê°•ë ¥í•œ large-v3 ëª¨ë¸ ì‚¬ìš©)
        # RunPod VRAMì´ ì¶©ë¶„í•˜ë¯€ë¡œ large-v3 ê¶Œì¥
        stt_engine = Transcriber(model_size="large-v3")
        
        # 3. ë³€í™˜ ìˆ˜í–‰
        results = stt_engine.transcribe(TEST_FILE)
        
        # 4. ê²°ê³¼ í™•ì¸
        print("\n--- [Final Result Sample] ---")
        print(results[:3] if results else "No result") # ì•ë¶€ë¶„ 3ê°œë§Œ ì¶œë ¥
    else:
        print(f"âŒ '{TEST_FILE}' not found. Please upload it via runpodctl.")
        print("Tip: runpodctl send test_audio.mp3")