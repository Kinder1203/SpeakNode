"""
SpeakNode Hybrid RAG (ê²€ìƒ‰ ì—”ì§„)
=================================
Vector RAG (ì˜ë¯¸ ê¸°ë°˜) + Graph RAG (êµ¬ì¡° ê¸°ë°˜) ê²°í•© ê²€ìƒ‰.
Agentì˜ Toolì´ ì´ ëª¨ë“ˆì„ í˜¸ì¶œí•˜ì—¬ íšŒì˜ DBì—ì„œ ì •ë³´ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
"""

from core.config import SpeakNodeConfig
from core.db.kuzu_manager import KuzuManager


class HybridRAG:
    """
    Hybrid RAG Engine
    - Vector Search: ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ê´€ë ¨ ë°œì–¸ ê²€ìƒ‰
    - Graph Search: PROPOSED, ASSIGNED_TO, RESULTED_IN ë“± êµ¬ì¡°ì  ê´€ê³„ íƒìƒ‰
    - Fusion: ë‘ ê²°ê³¼ë¥¼ í•©ì‚°í•˜ì—¬ ì¤‘ë³µ ì œê±° í›„ LLM ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    """

    def __init__(self, config: SpeakNodeConfig = None):
        self.config = config or SpeakNodeConfig()
        self._embedder = None  # Lazy Loading

    @property
    def embedder(self):
        """SentenceTransformer â€” ìµœì´ˆ ê²€ìƒ‰ ì‹œ 1íšŒë§Œ ë¡œë“œ"""
        if self._embedder is None:
            from sentence_transformers import SentenceTransformer
            print("   â³ Loading Embedding Model (HybridRAG)...")
            self._embedder = SentenceTransformer(self.config.embedding_model)
        return self._embedder

    # ================================================================
    # ğŸ” Vector RAG â€” ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
    # ================================================================

    def vector_search(self, query: str, db: KuzuManager, top_k: int = 5) -> list[dict]:
        """ìì—°ì–´ ì§ˆì˜ë¥¼ ë²¡í„°í™”í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ Utteranceë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        query_vec = self.embedder.encode(query).tolist()
        results = db.search_similar_utterances(query_vec, top_k=top_k)
        return results

    # ================================================================
    # ğŸ•¸ï¸ Graph RAG â€” êµ¬ì¡° ê¸°ë°˜ ê²€ìƒ‰
    # ================================================================

    def graph_search_topics(self, db: KuzuManager, keyword: str = "") -> list[dict]:
        """Topic ë…¸ë“œ ê²€ìƒ‰. keywordê°€ ìˆìœ¼ë©´ CONTAINS í•„í„°."""
        if keyword:
            rows = db.execute_cypher(
                "MATCH (t:Topic) WHERE t.title CONTAINS $kw OR t.summary CONTAINS $kw "
                "RETURN t.title, t.summary",
                {"kw": keyword}
            )
        else:
            rows = db.execute_cypher("MATCH (t:Topic) RETURN t.title, t.summary")
        return [{"title": r[0], "summary": r[1]} for r in rows]

    def graph_search_tasks(self, db: KuzuManager, person_name: str = "") -> list[dict]:
        """Task ë…¸ë“œ ê²€ìƒ‰. person_nameì´ ìˆìœ¼ë©´ í•´ë‹¹ ì¸ë¬¼ì˜ Taskë§Œ."""
        if person_name:
            return db.get_person_tasks(person_name)
        return db.get_all_tasks()

    def graph_search_decisions(self, db: KuzuManager, topic_title: str = "") -> list[dict]:
        """Decision ë…¸ë“œ ê²€ìƒ‰. topic_titleì´ ìˆìœ¼ë©´ í•´ë‹¹ Topicì˜ Decisionë§Œ."""
        if topic_title:
            return db.get_topic_decisions(topic_title)
        rows = db.execute_cypher("MATCH (d:Decision) RETURN d.description")
        return [{"description": r[0]} for r in rows]

    def graph_search_people(self, db: KuzuManager) -> list[dict]:
        """ëª¨ë“  Person ë…¸ë“œ ì¡°íšŒ."""
        rows = db.execute_cypher("MATCH (p:Person) RETURN p.name, p.role")
        return [{"name": r[0], "role": r[1]} for r in rows]

    def graph_search_meetings(self, db: KuzuManager) -> list[dict]:
        """ëª¨ë“  Meeting ë…¸ë“œ ì¡°íšŒ."""
        rows = db.execute_cypher(
            "MATCH (m:Meeting) RETURN m.id, m.title, m.date, m.source_file"
        )
        return [{"id": r[0], "title": r[1], "date": r[2], "source_file": r[3]} for r in rows]

    # ================================================================
    # ğŸ”„ Hybrid Search â€” ê²°í•© ê²€ìƒ‰
    # ================================================================

    def hybrid_search(self, query: str, db: KuzuManager, top_k: int = 5) -> dict:
        """
        Vector Search + Graph Search ê²°í•©.
        ì§ˆì˜ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ì–‘ìª½ ëª¨ë‘ ê²€ìƒ‰í•œ ë’¤ í†µí•© ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        # 1. Vector Search: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë°œì–¸ ê²€ìƒ‰
        vector_results = self.vector_search(query, db, top_k=top_k)

        # 2. Graph Search: êµ¬ì¡°ì  ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
        topics = self.graph_search_topics(db, keyword=query[:20] if len(query) > 5 else "")
        tasks = self.graph_search_tasks(db)
        decisions = self.graph_search_decisions(db)
        people = self.graph_search_people(db)

        graph_results = {
            "topics": topics,
            "tasks": tasks,
            "decisions": decisions,
            "people": people,
        }

        # 3. í†µí•© ì»¨í…ìŠ¤íŠ¸ ìƒì„± (LLM í”„ë¡¬í”„íŠ¸ì— ì£¼ì…í•  ë¬¸ìì—´)
        context_parts = []

        if vector_results:
            context_parts.append("## ê´€ë ¨ ë°œì–¸ (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰)")
            for vr in vector_results:
                context_parts.append(
                    f"- [{vr.get('start', 0):.1f}s] {vr['text']} (ìœ ì‚¬ë„: {vr.get('score', 0):.3f})"
                )

        if topics:
            context_parts.append("\n## ì£¼ì œ (Topic)")
            for t in topics:
                context_parts.append(f"- **{t['title']}**: {t.get('summary', '')}")

        if tasks:
            context_parts.append("\n## í•  ì¼ (Task)")
            for t in tasks:
                assignee = t.get("assignee", "ë¯¸ì§€ì •")
                context_parts.append(f"- {t['description']} (ë‹´ë‹¹: {assignee}, ìƒíƒœ: {t.get('status', '?')})")

        if decisions:
            context_parts.append("\n## ê²°ì • ì‚¬í•­ (Decision)")
            for d in decisions:
                context_parts.append(f"- {d['description']}")

        if people:
            context_parts.append("\n## ì°¸ì—¬ì")
            for p in people:
                context_parts.append(f"- {p['name']} ({p.get('role', 'Member')})")

        merged_context = "\n".join(context_parts) if context_parts else "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"

        return {
            "vector_results": vector_results,
            "graph_results": graph_results,
            "merged_context": merged_context,
        }
