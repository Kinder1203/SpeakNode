import streamlit as st
import os
import shutil
import time

st.set_page_config(page_title="SpeakNode Dashboard", layout="wide")

import matplotlib
matplotlib.use("Agg")

import view_components as vc
from core.pipeline import SpeakNodeEngine
from core.shared.share_manager import ShareManager
from core.db.kuzu_manager import KuzuManager
from core.config import SpeakNodeConfig, sanitize_chat_id, get_chat_db_path, list_chat_ids

_config = SpeakNodeConfig()
CHAT_DB_DIR = _config.db_base_dir
os.makedirs(CHAT_DB_DIR, exist_ok=True)

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
SHARED_CARDS_DIR = os.path.join(project_root, "shared_cards")
share_mgr = ShareManager(output_dir=SHARED_CARDS_DIR)

@st.cache_resource
def get_engine():
    print("ğŸ—ï¸ [App] Initializing SpeakNodeEngine...")
    return SpeakNodeEngine()

if 'analysis_result' not in st.session_state:
    st.session_state['analysis_result'] = None
if "active_chat_id" not in st.session_state:
    st.session_state["active_chat_id"] = "default"

vc.render_header()

with st.sidebar:
    st.header("ğŸ“‚ Workspace")
    uploaded_audio = st.file_uploader("íšŒì˜ ë…¹ìŒ íŒŒì¼ (ë¶„ì„ìš©)", type=["mp3", "wav", "m4a"])
    meeting_title_input = st.text_input(
        "íšŒì˜ ì œëª© (ì„ íƒ)",
        placeholder="ì˜ˆ: 2026-02-13 ì£¼ê°„ ìš´ì˜íšŒì˜",
        help="ë¹„ì›Œë‘ë©´ íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.",
    )
    
    st.divider()
    st.subheader("ğŸ’¬ Chat Sessions")

    chat_ids = list_chat_ids(_config)
    active_chat_id = sanitize_chat_id(st.session_state["active_chat_id"])
    if active_chat_id not in chat_ids:
        chat_ids = [active_chat_id] + chat_ids

    selected_chat_id = st.selectbox(
        "ì±„íŒ… ì„ íƒ",
        options=chat_ids if chat_ids else ["default"],
        index=(chat_ids.index(active_chat_id) if chat_ids else 0),
        help="ê°™ì€ ì±„íŒ…ì€ ëˆ„ì  ì €ì¥, ë‹¤ë¥¸ ì±„íŒ…ì€ ë‹¤ë¥¸ DBë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
    )

    if selected_chat_id != st.session_state["active_chat_id"]:
        st.session_state["active_chat_id"] = selected_chat_id
        st.session_state["analysis_result"] = None
        st.rerun()

    new_chat_name = st.text_input("ìƒˆ ì±„íŒ… ì´ë¦„", placeholder="ì˜ˆ: genomics_review")
    if st.button("â• ìƒˆ ì±„íŒ… ìƒì„±", use_container_width=True):
        new_chat_id = sanitize_chat_id(new_chat_name)
        st.session_state["active_chat_id"] = new_chat_id
        st.session_state["analysis_result"] = None
        st.success(f"ì±„íŒ… '{new_chat_id}' ìƒì„± ì™„ë£Œ")
        st.rerun()

    current_db_path = get_chat_db_path(st.session_state["active_chat_id"], _config)

    st.divider()
    st.subheader("âš™ï¸ System Settings")
    st.info(f"**Model:** qwen2.5:14b\n\n**Active Chat:** {st.session_state['active_chat_id']}")

    if st.button("ğŸ—‘ï¸ í˜„ì¬ ì±„íŒ… DB ì´ˆê¸°í™”", type="secondary"):
        try:
            st.session_state['analysis_result'] = None
            if os.path.exists(current_db_path):
                time.sleep(0.1)
                if os.path.isfile(current_db_path):
                    os.remove(current_db_path)
                else:
                    shutil.rmtree(current_db_path)
            st.success("í˜„ì¬ ì±„íŒ… DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            time.sleep(0.5)
            st.rerun()
        except Exception as e:
            st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

if uploaded_audio:
    st.audio(uploaded_audio)
    
    if st.button("ğŸš€ íšŒì˜ ë¶„ì„ ì‹œì‘", type="primary"):
        safe_filename = os.path.basename(uploaded_audio.name)
        temp_audio = os.path.join(project_root, f"temp_{safe_filename}")
        
        with open(temp_audio, "wb") as f:
            f.write(uploaded_audio.getbuffer())
        
        with st.status("ğŸ” ë¶„ì„ ì¤‘...", expanded=True) as status:
            try:
                engine = get_engine()
                result = engine.process(
                    temp_audio,
                    db_path=current_db_path,
                    meeting_title=meeting_title_input,
                )
                st.session_state['analysis_result'] = result
                
                if result:
                    status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
                else:
                    status.update(label="âš ï¸ ë‚´ìš© ì—†ìŒ", state="error")
                    st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
                print(f"âŒ Error detail: {e}")
                status.update(label="âŒ ì‹¤íŒ¨", state="error")
        
        if os.path.exists(temp_audio):
            try:
                os.remove(temp_audio)
            except OSError as e:
                print(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

elif not st.session_state['analysis_result']: 
    st.info("íšŒì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, ê¸°ì¡´ ê·¸ë˜í”„ ì´ë¯¸ì§€ë¥¼ í†µí•´ ë³µì›í•˜ì„¸ìš”.")
    
    restored_data = vc.render_import_card_ui(share_mgr)
    if restored_data:
        bundle_format = restored_data.get("format") if isinstance(restored_data, dict) else ""
        if bundle_format == "speaknode_graph_bundle_v1":
            restored_analysis = restored_data.get("analysis_result", {})
            restored_graph_dump = restored_data.get("graph_dump", {})
        else:
            # Backward compatibility for legacy PNG format.
            restored_analysis = restored_data
            restored_graph_dump = {}

        st.session_state['analysis_result'] = restored_analysis
        
        db_mgr = None
        try:
            db_mgr = KuzuManager(current_db_path, config=_config)
            if restored_graph_dump:
                db_mgr.restore_graph_dump(restored_graph_dump)
                st.success("âœ… ì „ì²´ ê·¸ë˜í”„ ë°ì´í„° ë³µì› ë° DB ë™ê¸°í™” ì™„ë£Œ!")
            else:
                db_mgr.ingest_data(restored_analysis)
                st.success("âœ… ë¶„ì„ ë°ì´í„° ë³µì› ë° DB ë™ê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            st.error(f"âŒ DB ë³µì› ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            if db_mgr:
                db_mgr.close()
            
        time.sleep(0.5)
        st.rerun()

if st.session_state['analysis_result']:
    result = st.session_state['analysis_result']
    
    st.divider()
    vc.display_analysis_cards(result)
    
    tab_graph, tab_agent, tab_save = st.tabs(["ğŸ•¸ï¸ Knowledge Graph", "ğŸ¤– AI Agent", "ğŸ’¾ ì €ì¥"])
    
    with tab_graph:
        if os.path.exists(current_db_path):
            vc.render_graph_view(current_db_path)
            st.divider()
            vc.render_graph_editor(current_db_path)
        else:
            st.info("í˜„ì¬ ì±„íŒ…ì—ëŠ” ì•„ì§ ì €ì¥ëœ ê·¸ë˜í”„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab_agent:
        st.subheader("ğŸ¤– AI Agent â€” íšŒì˜ ë°ì´í„° ì§ˆì˜")
        st.caption("íšŒì˜ ë‚´ìš©ì— ëŒ€í•´ ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”. ì´ë©”ì¼ ì´ˆì•ˆ ì‘ì„±ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        history_key = f"agent_chat_history::{st.session_state['active_chat_id']}"
        
        if history_key not in st.session_state:
            st.session_state[history_key] = []
        chat_history = st.session_state[history_key]
        
        for msg in chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
        
        if not chat_history:
            st.markdown("**ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸:**")
            example_cols = st.columns(3)
            examples = [
                "ì´ë²ˆ íšŒì˜ì—ì„œ ê²°ì •ëœ ì‚¬í•­ì„ ì•Œë ¤ì¤˜",
                "ëˆ„ê°€ ì–´ë–¤ í•  ì¼ì„ ë§¡ì•˜ì–´?",
                "íšŒì˜ ê²°ê³¼ë¥¼ íŒ€ì›ì—ê²Œ ì´ë©”ì¼ë¡œ ë³´ë‚´ì¤˜",
            ]
            for i, example in enumerate(examples):
                if example_cols[i].button(example, key=f"example_{i}"):
                    st.session_state["_pending_agent_query"] = example
                    st.rerun()
        
        pending_query = st.session_state.pop("_pending_agent_query", None)
        user_input = st.chat_input("íšŒì˜ ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...")
        query = pending_query or user_input
        
        if query:
            chat_history.append({"role": "user", "content": query})
            with st.chat_message("user"):
                st.markdown(query)
            
            with st.chat_message("assistant"):
                with st.spinner("ğŸ” ë¶„ì„ ì¤‘..."):
                    try:
                        engine = get_engine()
                        agent = engine.create_agent(db_path=current_db_path)
                        
                        from langchain_core.messages import HumanMessage as HM, AIMessage as AM
                        lc_history = []
                        for msg in chat_history[:-1]:
                            if msg["role"] == "user":
                                lc_history.append(HM(content=msg["content"]))
                            else:
                                lc_history.append(AM(content=msg["content"]))
                        
                        response = agent.query(query, chat_history=lc_history)
                        st.markdown(response)
                        chat_history.append({"role": "assistant", "content": response})
                    except Exception as e:
                        error_msg = f"âŒ Agent ì˜¤ë¥˜: {e}"
                        st.error(error_msg)
                        chat_history.append({"role": "assistant", "content": error_msg})
        
        if chat_history:
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", key="clear_agent_chat"):
                st.session_state[history_key] = []
                st.rerun()

    with tab_save:
        st.subheader("ğŸ’¾ ì§€ì‹ ê·¸ë˜í”„ ì´ë¯¸ì§€ ì €ì¥")
        st.info("í˜„ì¬ ê²°ê³¼ë¥¼ ì§€ì‹ ê·¸ë˜í”„ ì´ë¯¸ì§€ë¡œ ì €ì¥í•©ë‹ˆë‹¤. PNGì— ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ê³µìœ  ì‹œ DB ë³µì›ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        include_embeddings = st.checkbox(
            "ì„ë² ë”© í¬í•¨ ì €ì¥ (íŒŒì¼ í¬ê¸° ì¦ê°€, Vector ê²€ìƒ‰ í’ˆì§ˆ ìœ ì§€)",
            value=False,
            key="save_with_embeddings",
        )
        buf = vc.generate_static_graph_image(
            current_db_path,
            result,
            include_embeddings=include_embeddings,
        )
        if buf:
            st.download_button("ğŸ“¥ ê·¸ë˜í”„ ë‹¤ìš´ë¡œë“œ", buf, "graph.png", "image/png")
